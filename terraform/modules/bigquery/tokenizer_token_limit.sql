select 'bigcode/starcoder2-3b' as tokenizer, 16384 as `limit`, 'group-query attention, sliding window attention of 4,096 tokens, training using fill-in-the-middle objective' as associated_model_notes
